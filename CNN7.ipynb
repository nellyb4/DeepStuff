{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3vfj7GZ-7LY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3057a6f-d8cd-41cc-df89-ceea13001e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torchinfo import summary\n",
        "\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Setting the working directory:\n",
        "\n",
        "if not('Nilly' in os.getcwd() or '472data' in os.getcwd()):\n",
        "  # os.chdir('drive/MyDrive/Nilly/')\n",
        "  os.chdir('drive/MyDrive/Nilly/')"
      ],
      "metadata": {
        "id": "8ffDfjoeB4_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 60\n",
        "lr = 0.001\n",
        "b_s = 40\n",
        "\n",
        "try_num = 3"
      ],
      "metadata": {
        "id": "w5JApLyPQb3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = 'COMP472-AK_15-main/'\n",
        "save_dir = 'model_' + str(try_num) + '/'\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "  os.mkdir(save_dir)"
      ],
      "metadata": {
        "id": "Ly99627d_PTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "  transforms.Resize([224, 224]),\n",
        "  # transforms.CenterCrop(224),\n",
        "  transforms.Grayscale(num_output_channels=1),\n",
        "  transforms.ToTensor(),\n",
        "  # transforms.RandomRotation(30),\n",
        "  # transforms.RandomHorizontalFlip(),\n",
        "  transforms.Normalize(mean=[0.5], std=[0.2]), # Use single-channel values for grayscale\n",
        "  ])\n",
        "test_transform = transforms.Compose([\n",
        "  transforms.Resize([224, 224]),\n",
        "  transforms.Grayscale(num_output_channels=1),\n",
        "  # transforms.CenterCrop(255),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean=[0.5], std=[0.2]), # Use single-channel values for grayscale\n",
        "  ])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=dir + 'dataset/train', transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=dir + 'dataset/test', transform=transform)\n",
        "\n",
        "# train_data, val_data = train_test_split(train_dataset, test_size=0.2, random_state=42, stratify=train_dataset.targets)"
      ],
      "metadata": {
        "id": "Cma7JKCjABvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: split the train_dataset into validation set and train set\n",
        "\n",
        "# Split the train_dataset into train and validation sets\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n"
      ],
      "metadata": {
        "id": "XBNt4pUcY3Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: make torch data loader from the dataset of the last block\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=b_s, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=b_s, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=b_s, shuffle=True)"
      ],
      "metadata": {
        "id": "Xhiv7bg1GgTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "AxwXfUoc0hED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet7(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(ConvNet7, self).__init__()\n",
        "        # Define the convolutional layer\n",
        "        self.conv_net = nn.Sequential(\n",
        "\n",
        "                                 nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(7, 7), stride=1, padding='same'),\n",
        "                                 nn.BatchNorm2d(32),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.3),\n",
        "\n",
        "                                 nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(7, 7), stride=1, padding='same'),\n",
        "                                 nn.BatchNorm2d(64),\n",
        "                                 nn.ReLU(),\n",
        "\n",
        "                                 nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
        "                                 nn.Dropout(0.3),\n",
        "\n",
        "                                 nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(7, 7), stride=1, padding='same'),\n",
        "                                 nn.BatchNorm2d(128),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.3),\n",
        "\n",
        "                                 nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(7, 7), stride=1, padding='same'),\n",
        "                                 nn.BatchNorm2d(128),\n",
        "                                 nn.ReLU(),\n",
        "\n",
        "                                 nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
        "                                 nn.Dropout(0.3),\n",
        "\n",
        "                                 # add layers:\n",
        "                                 nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(7, 7), stride=1, padding='same'),\n",
        "                                 nn.BatchNorm2d(128),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.3),\n",
        "\n",
        "                                 nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(7, 7), stride=1, padding='same'),\n",
        "                                 nn.BatchNorm2d(128),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.3),\n",
        "\n",
        "                                 nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(7, 7), stride=1, padding='same'),\n",
        "                                 nn.BatchNorm2d(64),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.3),\n",
        "\n",
        "                                 nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
        "                                 nn.Dropout(0.3),\n",
        "\n",
        "                                 nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(7, 7), stride=1, padding='same'),\n",
        "                                 nn.BatchNorm2d(32),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.3),\n",
        "\n",
        "                                 nn.Conv2d(in_channels=32, out_channels=16, kernel_size=(7, 7), stride=1, padding='same'),\n",
        "                                 nn.BatchNorm2d(16),\n",
        "                                 nn.ReLU(),\n",
        "\n",
        "                                 nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
        "                                 nn.Dropout(0.3),\n",
        "\n",
        "                                 nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(7, 7), stride=1, padding='same'),\n",
        "                                 nn.BatchNorm2d(8),\n",
        "                                 nn.ReLU(),\n",
        "\n",
        "                                 nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
        "                                 nn.Dropout(0.3),\n",
        "\n",
        "                                 )\n",
        "        self.fc = nn.Sequential(\n",
        "                                nn.Linear(8 * 7 * 7, 128),\n",
        "                                nn.ReLU(),\n",
        "\n",
        "                                nn.Linear(128, 64),\n",
        "                                nn.ReLU(),\n",
        "\n",
        "                                nn.Linear(64, num_classes),\n",
        "                                nn.ReLU(),\n",
        "                                )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through the convolutional layer\n",
        "        x = self.conv_net(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "# model = ConvNet()\n",
        "# output = model(images)\n"
      ],
      "metadata": {
        "id": "ssVpiLEhjcRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet7()\n",
        "# output = model(images)\n",
        "summary(model, input_size=(b_s, 1, 224, 224))"
      ],
      "metadata": {
        "id": "yRzQECnwMKrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5a0444-6dee-47f6-f807-471a594f1a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ConvNet7                                 [40, 5]                   --\n",
              "├─Sequential: 1-1                        [40, 8, 7, 7]             --\n",
              "│    └─Conv2d: 2-1                       [40, 32, 224, 224]        1,600\n",
              "│    └─BatchNorm2d: 2-2                  [40, 32, 224, 224]        64\n",
              "│    └─ReLU: 2-3                         [40, 32, 224, 224]        --\n",
              "│    └─Dropout: 2-4                      [40, 32, 224, 224]        --\n",
              "│    └─Conv2d: 2-5                       [40, 64, 224, 224]        100,416\n",
              "│    └─BatchNorm2d: 2-6                  [40, 64, 224, 224]        128\n",
              "│    └─ReLU: 2-7                         [40, 64, 224, 224]        --\n",
              "│    └─MaxPool2d: 2-8                    [40, 64, 112, 112]        --\n",
              "│    └─Dropout: 2-9                      [40, 64, 112, 112]        --\n",
              "│    └─Conv2d: 2-10                      [40, 128, 112, 112]       401,536\n",
              "│    └─BatchNorm2d: 2-11                 [40, 128, 112, 112]       256\n",
              "│    └─ReLU: 2-12                        [40, 128, 112, 112]       --\n",
              "│    └─Dropout: 2-13                     [40, 128, 112, 112]       --\n",
              "│    └─Conv2d: 2-14                      [40, 128, 112, 112]       802,944\n",
              "│    └─BatchNorm2d: 2-15                 [40, 128, 112, 112]       256\n",
              "│    └─ReLU: 2-16                        [40, 128, 112, 112]       --\n",
              "│    └─MaxPool2d: 2-17                   [40, 128, 56, 56]         --\n",
              "│    └─Dropout: 2-18                     [40, 128, 56, 56]         --\n",
              "│    └─Conv2d: 2-19                      [40, 128, 56, 56]         802,944\n",
              "│    └─BatchNorm2d: 2-20                 [40, 128, 56, 56]         256\n",
              "│    └─ReLU: 2-21                        [40, 128, 56, 56]         --\n",
              "│    └─Dropout: 2-22                     [40, 128, 56, 56]         --\n",
              "│    └─Conv2d: 2-23                      [40, 128, 56, 56]         802,944\n",
              "│    └─BatchNorm2d: 2-24                 [40, 128, 56, 56]         256\n",
              "│    └─ReLU: 2-25                        [40, 128, 56, 56]         --\n",
              "│    └─Dropout: 2-26                     [40, 128, 56, 56]         --\n",
              "│    └─Conv2d: 2-27                      [40, 64, 56, 56]          401,472\n",
              "│    └─BatchNorm2d: 2-28                 [40, 64, 56, 56]          128\n",
              "│    └─ReLU: 2-29                        [40, 64, 56, 56]          --\n",
              "│    └─Dropout: 2-30                     [40, 64, 56, 56]          --\n",
              "│    └─MaxPool2d: 2-31                   [40, 64, 28, 28]          --\n",
              "│    └─Dropout: 2-32                     [40, 64, 28, 28]          --\n",
              "│    └─Conv2d: 2-33                      [40, 32, 28, 28]          100,384\n",
              "│    └─BatchNorm2d: 2-34                 [40, 32, 28, 28]          64\n",
              "│    └─ReLU: 2-35                        [40, 32, 28, 28]          --\n",
              "│    └─Dropout: 2-36                     [40, 32, 28, 28]          --\n",
              "│    └─Conv2d: 2-37                      [40, 16, 28, 28]          25,104\n",
              "│    └─BatchNorm2d: 2-38                 [40, 16, 28, 28]          32\n",
              "│    └─ReLU: 2-39                        [40, 16, 28, 28]          --\n",
              "│    └─MaxPool2d: 2-40                   [40, 16, 14, 14]          --\n",
              "│    └─Dropout: 2-41                     [40, 16, 14, 14]          --\n",
              "│    └─Conv2d: 2-42                      [40, 8, 14, 14]           6,280\n",
              "│    └─BatchNorm2d: 2-43                 [40, 8, 14, 14]           16\n",
              "│    └─ReLU: 2-44                        [40, 8, 14, 14]           --\n",
              "│    └─MaxPool2d: 2-45                   [40, 8, 7, 7]             --\n",
              "│    └─Dropout: 2-46                     [40, 8, 7, 7]             --\n",
              "├─Sequential: 1-2                        [40, 5]                   --\n",
              "│    └─Linear: 2-47                      [40, 128]                 50,304\n",
              "│    └─ReLU: 2-48                        [40, 128]                 --\n",
              "│    └─Linear: 2-49                      [40, 64]                  8,256\n",
              "│    └─ReLU: 2-50                        [40, 64]                  --\n",
              "│    └─Linear: 2-51                      [40, 5]                   325\n",
              "│    └─ReLU: 2-52                        [40, 5]                   --\n",
              "==========================================================================================\n",
              "Total params: 3,505,965\n",
              "Trainable params: 3,505,965\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (T): 1.06\n",
              "==========================================================================================\n",
              "Input size (MB): 8.03\n",
              "Forward/backward pass size (MB): 5805.43\n",
              "Params size (MB): 14.02\n",
              "Estimated Total Size (MB): 5827.48\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ED_model(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=5):\n",
        "        super(ED_model, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding='same', bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.dropout1 = nn.Dropout(p=0.3)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, stride=1, padding='same', bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.dropout2 = nn.Dropout(p=0.3)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding='same', bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 48x48 -> 24x24\n",
        "        self.dropout3 = nn.Dropout(p=0.3)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding='same', bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.dropout4 = nn.Dropout(p=0.3)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding='same', bias=False)\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "        self.dropout5 = nn.Dropout(p=0.3)\n",
        "\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding='same', bias=False)\n",
        "        self.bn6 = nn.BatchNorm2d(128)\n",
        "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 24x24 -> 12x12\n",
        "        self.dropout6 = nn.Dropout(p=0.3)\n",
        "\n",
        "        self.conv7 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.bn7 = nn.BatchNorm2d(64)\n",
        "        self.dropout7 = nn.Dropout(p=0.3)\n",
        "\n",
        "        self.conv8 = nn.Conv2d(in_channels=64, out_channels=16, kernel_size=3, stride=2, padding=0, bias=False)\n",
        "        self.bn8 = nn.BatchNorm2d(16)\n",
        "        self.max_pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # 12x12 -> 6x6\n",
        "        self.dropout8 = nn.Dropout(p=0.3)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=6*6*16, out_features=256)\n",
        "        self.fc2 = nn.Linear(in_features=256, out_features=32)\n",
        "        self.fc3 = nn.Linear(32, out_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout1(x) # <- block 1\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x) # <- block 2\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.max_pool1(x)\n",
        "        x = self.dropout3(x) # <- block 3\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout4(x) # <- block 4\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout5(x) # <- block 5\n",
        "        x = self.conv6(x)\n",
        "        x = self.bn6(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.max_pool2(x)\n",
        "        x = self.dropout6(x) # <- block 6\n",
        "\n",
        "        x = self.conv7(x)\n",
        "        x = self.bn7(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout7(x) # <- block 7\n",
        "        x = self.conv8(x)\n",
        "        x = self.bn8(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.max_pool3(x)\n",
        "        x = self.dropout8(x) # <- block 8\n",
        "\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "3ZjSNe1R-gDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ED_model(in_channels=1, out_channels=5)\n",
        "summary(model, input_size=(32, 1, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUd3EB4V-sZB",
        "outputId": "7ed8c624-8887-4ece-9090-14ecf55a8952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ED_model                                 [32, 5]                   --\n",
              "├─Conv2d: 1-1                            [32, 16, 224, 224]        144\n",
              "├─BatchNorm2d: 1-2                       [32, 16, 224, 224]        32\n",
              "├─Dropout: 1-3                           [32, 16, 224, 224]        --\n",
              "├─Conv2d: 1-4                            [32, 64, 224, 224]        9,216\n",
              "├─BatchNorm2d: 1-5                       [32, 64, 224, 224]        128\n",
              "├─Dropout: 1-6                           [32, 64, 224, 224]        --\n",
              "├─Conv2d: 1-7                            [32, 128, 224, 224]       73,728\n",
              "├─BatchNorm2d: 1-8                       [32, 128, 224, 224]       256\n",
              "├─MaxPool2d: 1-9                         [32, 128, 112, 112]       --\n",
              "├─Dropout: 1-10                          [32, 128, 112, 112]       --\n",
              "├─Conv2d: 1-11                           [32, 128, 112, 112]       147,456\n",
              "├─BatchNorm2d: 1-12                      [32, 128, 112, 112]       256\n",
              "├─Dropout: 1-13                          [32, 128, 112, 112]       --\n",
              "├─Conv2d: 1-14                           [32, 128, 112, 112]       147,456\n",
              "├─BatchNorm2d: 1-15                      [32, 128, 112, 112]       256\n",
              "├─Dropout: 1-16                          [32, 128, 112, 112]       --\n",
              "├─Conv2d: 1-17                           [32, 128, 112, 112]       147,456\n",
              "├─BatchNorm2d: 1-18                      [32, 128, 112, 112]       256\n",
              "├─MaxPool2d: 1-19                        [32, 128, 56, 56]         --\n",
              "├─Dropout: 1-20                          [32, 128, 56, 56]         --\n",
              "├─Conv2d: 1-21                           [32, 64, 28, 28]          73,728\n",
              "├─BatchNorm2d: 1-22                      [32, 64, 28, 28]          128\n",
              "├─Dropout: 1-23                          [32, 64, 28, 28]          --\n",
              "├─Conv2d: 1-24                           [32, 16, 13, 13]          9,216\n",
              "├─BatchNorm2d: 1-25                      [32, 16, 13, 13]          32\n",
              "├─MaxPool2d: 1-26                        [32, 16, 6, 6]            --\n",
              "├─Dropout: 1-27                          [32, 16, 6, 6]            --\n",
              "├─Linear: 1-28                           [32, 256]                 147,712\n",
              "├─Linear: 1-29                           [32, 32]                  8,224\n",
              "├─Linear: 1-30                           [32, 5]                   165\n",
              "==========================================================================================\n",
              "Total params: 765,845\n",
              "Trainable params: 765,845\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 312.88\n",
              "==========================================================================================\n",
              "Input size (MB): 6.42\n",
              "Forward/backward pass size (MB): 7836.94\n",
              "Params size (MB): 3.06\n",
              "Estimated Total Size (MB): 7846.43\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw9df6GQM0y2",
        "outputId": "2793c424-9de5-46b9-af3c-c524a96b2fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_train_losses = []\n",
        "total_val_losses = []\n",
        "total_train_accuracy = []\n",
        "total_val_accuracy = []\n",
        "total_train_f1 = []\n",
        "total_val_f1 = []\n",
        "learning_rate_tracker = []\n",
        "\n",
        "def train(model, optimizer, criterion, scheduler, EPOCHS):\n",
        "\n",
        "  cur_loss = 9999\n",
        "\n",
        "  for epoch in tqdm(range(1, EPOCHS+1)):\n",
        "\n",
        "    # Train model\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    train_accuracy = []\n",
        "    train_f1 = []\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      img_batch, label_batch = batch   #img [B,3,H,W], label[B,N_CLASSES]\n",
        "      img_batch = img_batch.to(device)\n",
        "      label_batch = label_batch.type(torch.LongTensor).to(device)\n",
        "\n",
        "      #Train model\n",
        "      output = model(img_batch) # output: [B, 7, H, W]\n",
        "\n",
        "\n",
        "      # print(img_batch)\n",
        "      loss = criterion(output, label_batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      #Add current loss to temporary list (after 1 epoch take avg of all batch losses)\n",
        "      preds = torch.argmax(torch.exp(output), dim=1)\n",
        "\n",
        "      f1 = f1_score(preds.cpu(), label_batch.cpu(), average='macro')\n",
        "      acc = torch.sum(preds == label_batch) / len(preds)\n",
        "      train_losses.append(loss.item())\n",
        "      train_accuracy.append(acc.cpu())\n",
        "      train_f1.append(f1)\n",
        "      print('\\r', f'TRAIN Epoch: {epoch}, batch: {i} | Batch metrics | loss: {loss.item():.4f}, f1: {f1:.3f}, accuracy: {acc:.3f}', end='', flush=True)\n",
        "\n",
        "\n",
        "    print()\n",
        "    print(f'TRAIN Epoch: {epoch} | Epoch metrics | loss: {np.mean(train_losses):.4f}, f1: {np.mean(train_f1):.3f}, accuracy: {np.mean(train_accuracy):.3f}, learning rate: {optimizer.state_dict()[\"param_groups\"][0][\"lr\"]:.6f}')\n",
        "    total_train_losses.append(np.mean(train_losses))\n",
        "    total_train_accuracy.append(np.mean(train_accuracy))\n",
        "    total_train_f1.append(np.mean(train_f1))\n",
        "\n",
        "    #Update learning rate\n",
        "    learning_rate_tracker.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
        "    scheduler.step()\n",
        "\n",
        "    # Validate model\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    val_accuracy = []\n",
        "    val_f1 = []\n",
        "\n",
        "    for i, batch in enumerate(val_dataloader):\n",
        "      #Extract data, labels\n",
        "      img_batch, label_batch = batch\n",
        "      img_batch = img_batch.to(device)\n",
        "      label_batch = label_batch.type(torch.LongTensor).to(device)\n",
        "\n",
        "      #Validate model\n",
        "      with torch.cuda.amp.autocast():\n",
        "          output = model(img_batch)\n",
        "          loss = criterion(output, label_batch)\n",
        "\n",
        "      #Add current loss to temporary list (after 1 epoch take avg of all batch losses)\n",
        "      preds = torch.argmax(output, dim=1)\n",
        "      f1 = f1_score(preds.cpu(), label_batch.cpu(), average='macro')\n",
        "      acc = torch.sum(preds == label_batch) / len(preds)\n",
        "      val_losses.append(loss.item())\n",
        "      val_accuracy.append(acc.cpu())\n",
        "      val_f1.append(f1)\n",
        "\n",
        "\n",
        "    # Update global metrics\n",
        "    print(f'VALIDATION  Epoch: {epoch} | Epoch metrics | loss: {np.mean(val_losses):.4f}, f1: {np.mean(val_f1):.3f}, accuracy: {np.mean(val_accuracy):.3f}')\n",
        "    print('-'*50)\n",
        "    total_val_losses.append(np.mean(val_losses))\n",
        "    total_val_accuracy.append(np.mean(val_accuracy))\n",
        "    total_val_f1.append(np.mean(val_f1))\n",
        "\n",
        "    # Save the results so far\n",
        "    temp_df = pd.DataFrame(list(zip(total_train_losses, total_val_losses, total_train_f1, total_val_f1,\n",
        "                                total_train_accuracy, total_val_accuracy)),\n",
        "                        columns = ['train_loss', 'val_loss', 'train_f1', 'test_f1', 'train_accuracy',\n",
        "                                  'test_accuracy'])\n",
        "    temp_df.to_csv(save_dir + 'train_val_measures')\n",
        "\n",
        "    if np.mean(val_losses) < cur_loss:\n",
        "      print('saving model')\n",
        "      torch.save(model.state_dict(), save_dir + 'model.pt')\n",
        "      cur_loss = np.mean(val_losses)\n"
      ],
      "metadata": {
        "id": "7vObFtVpdb9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1) # Use dynamic learning rate\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "ig_bLtBKKNTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, optimizer, criterion, scheduler, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5lELbCwORCE",
        "outputId": "a26013b1-cef0-4532-8038-dfbe8363aa75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/60 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TRAIN Epoch: 1, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.000, accuracy: 0.000\n",
            "TRAIN Epoch: 1 | Epoch metrics | loss: 1.6095, f1: 0.061, accuracy: 0.163, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/60 [20:09<19:49:48, 1209.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 1 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            "saving model\n",
            " TRAIN Epoch: 2, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.042, accuracy: 0.091\n",
            "TRAIN Epoch: 2 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/60 [21:30<8:47:31, 545.72s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 2 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 3, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.000, accuracy: 0.000\n",
            "TRAIN Epoch: 3 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.166, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 3/60 [22:50<5:16:07, 332.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 3 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 4, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.000, accuracy: 0.000\n",
            "TRAIN Epoch: 4 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.166, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 4/60 [24:09<3:37:20, 232.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 4 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 5, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.086, accuracy: 0.273\n",
            "TRAIN Epoch: 5 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/60 [25:27<2:42:18, 177.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 5 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 6, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.107, accuracy: 0.364\n",
            "TRAIN Epoch: 6 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.170, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 6/60 [26:40<2:07:20, 141.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 6 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 7, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.062, accuracy: 0.182\n",
            "TRAIN Epoch: 7 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 7/60 [27:52<1:45:05, 118.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 7 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 8, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.077, accuracy: 0.182\n",
            "TRAIN Epoch: 8 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 8/60 [29:05<1:30:21, 104.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 8 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 9, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.000, accuracy: 0.000\n",
            "TRAIN Epoch: 9 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.166, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 9/60 [30:17<1:20:02, 94.17s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 9 | Epoch metrics | loss: 1.6094, f1: 0.060, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 10, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.000, accuracy: 0.000\n",
            "TRAIN Epoch: 10 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.166, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 10/60 [31:30<1:12:54, 87.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 10 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 11, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 11 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 11/60 [32:42<1:07:37, 82.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 11 | Epoch metrics | loss: 1.6094, f1: 0.060, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 12, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.176, accuracy: 0.545\n",
            "TRAIN Epoch: 12 | Epoch metrics | loss: 1.6094, f1: 0.058, accuracy: 0.171, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 12/60 [33:54<1:03:36, 79.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 12 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 13, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.062, accuracy: 0.182\n",
            "TRAIN Epoch: 13 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 13/60 [35:08<1:00:56, 77.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 13 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 14, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 14 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 14/60 [36:22<58:47, 76.69s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 14 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 15, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.042, accuracy: 0.091\n",
            "TRAIN Epoch: 15 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.167, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 15/60 [37:36<56:59, 75.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 15 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 16, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.107, accuracy: 0.364\n",
            "TRAIN Epoch: 16 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.170, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 16/60 [38:51<55:29, 75.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 16 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 17, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.086, accuracy: 0.273\n",
            "TRAIN Epoch: 17 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 17/60 [40:04<53:39, 74.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 17 | Epoch metrics | loss: 1.6094, f1: 0.076, accuracy: 0.189\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 18, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.086, accuracy: 0.273\n",
            "TRAIN Epoch: 18 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 18/60 [41:17<52:04, 74.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 18 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 19, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 19 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 19/60 [42:30<50:28, 73.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 19 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 20, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.000, accuracy: 0.000\n",
            "TRAIN Epoch: 20 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.166, learning rate: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 20/60 [43:42<48:53, 73.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 20 | Epoch metrics | loss: 1.6094, f1: 0.076, accuracy: 0.189\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 21, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.107, accuracy: 0.273\n",
            "TRAIN Epoch: 21 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 21/60 [44:55<47:31, 73.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 21 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 22, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 22 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 22/60 [46:07<46:08, 72.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 22 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 23, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 23 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 23/60 [47:19<44:50, 72.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 23 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 24, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 24 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 24/60 [48:32<43:36, 72.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 24 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 25, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 25 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 25/60 [49:44<42:20, 72.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 25 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 26, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.042, accuracy: 0.091\n",
            "TRAIN Epoch: 26 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 26/60 [50:57<41:09, 72.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 26 | Epoch metrics | loss: 1.6094, f1: 0.076, accuracy: 0.189\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 27, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.077, accuracy: 0.182\n",
            "TRAIN Epoch: 27 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 27/60 [52:10<39:54, 72.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 27 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 28, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 28 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 28/60 [53:22<38:43, 72.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 28 | Epoch metrics | loss: 1.6094, f1: 0.076, accuracy: 0.189\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 29, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 29 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 29/60 [54:36<37:37, 72.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 29 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 30, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.062, accuracy: 0.182\n",
            "TRAIN Epoch: 30 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 30/60 [55:48<36:21, 72.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 30 | Epoch metrics | loss: 1.6094, f1: 0.060, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 31, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.062, accuracy: 0.182\n",
            "TRAIN Epoch: 31 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 31/60 [57:01<35:12, 72.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 31 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 32, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 32 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 32/60 [58:14<33:56, 72.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 32 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 33, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.086, accuracy: 0.273\n",
            "TRAIN Epoch: 33 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 33/60 [59:26<32:40, 72.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 33 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 34, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.062, accuracy: 0.182\n",
            "TRAIN Epoch: 34 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 34/60 [1:00:39<31:31, 72.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 34 | Epoch metrics | loss: 1.6094, f1: 0.076, accuracy: 0.189\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 35, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 35 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 35/60 [1:01:51<30:16, 72.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 35 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 36, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.000, accuracy: 0.000\n",
            "TRAIN Epoch: 36 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.166, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 36/60 [1:03:04<29:02, 72.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 36 | Epoch metrics | loss: 1.6094, f1: 0.076, accuracy: 0.189\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 37, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.086, accuracy: 0.273\n",
            "TRAIN Epoch: 37 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 37/60 [1:04:17<27:51, 72.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 37 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 38, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 38 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 38/60 [1:05:29<26:38, 72.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 38 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 39, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.042, accuracy: 0.091\n",
            "TRAIN Epoch: 39 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 39/60 [1:06:43<25:29, 72.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 39 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 40, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.042, accuracy: 0.091\n",
            "TRAIN Epoch: 40 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 40/60 [1:07:55<24:15, 72.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 40 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 41, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 41 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 41/60 [1:09:08<23:03, 72.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 41 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 42, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.042, accuracy: 0.091\n",
            "TRAIN Epoch: 42 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 42/60 [1:10:20<21:47, 72.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 42 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 43, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.086, accuracy: 0.273\n",
            "TRAIN Epoch: 43 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 43/60 [1:11:32<20:31, 72.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 43 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 44, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.062, accuracy: 0.182\n",
            "TRAIN Epoch: 44 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 44/60 [1:12:45<19:20, 72.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 44 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 45, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.086, accuracy: 0.273\n",
            "TRAIN Epoch: 45 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 45/60 [1:13:57<18:05, 72.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 45 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 46, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.033, accuracy: 0.091\n",
            "TRAIN Epoch: 46 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 46/60 [1:15:09<16:53, 72.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 46 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 47, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.086, accuracy: 0.273\n",
            "TRAIN Epoch: 47 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 47/60 [1:16:22<15:41, 72.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 47 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 48, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.062, accuracy: 0.182\n",
            "TRAIN Epoch: 48 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 48/60 [1:17:34<14:27, 72.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 48 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 49, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.062, accuracy: 0.182\n",
            "TRAIN Epoch: 49 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.168, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 49/60 [1:18:46<13:15, 72.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 49 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 50, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.042, accuracy: 0.091\n",
            "TRAIN Epoch: 50 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.167, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 50/60 [1:19:59<12:03, 72.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 50 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 51, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.062, accuracy: 0.182\n",
            "TRAIN Epoch: 51 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 51/60 [1:21:11<10:51, 72.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 51 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 52, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.000, accuracy: 0.000\n",
            "TRAIN Epoch: 52 | Epoch metrics | loss: 1.6094, f1: 0.056, accuracy: 0.166, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 52/60 [1:22:24<09:38, 72.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 52 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 53, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.077, accuracy: 0.182\n",
            "TRAIN Epoch: 53 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 53/60 [1:23:36<08:25, 72.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 53 | Epoch metrics | loss: 1.6094, f1: 0.076, accuracy: 0.189\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 54, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.107, accuracy: 0.273\n",
            "TRAIN Epoch: 54 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 54/60 [1:24:48<07:14, 72.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 54 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 55, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.077, accuracy: 0.182\n",
            "TRAIN Epoch: 55 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 55/60 [1:26:00<06:01, 72.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 55 | Epoch metrics | loss: 1.6094, f1: 0.076, accuracy: 0.189\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 56, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.086, accuracy: 0.273\n",
            "TRAIN Epoch: 56 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 56/60 [1:27:13<04:49, 72.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 56 | Epoch metrics | loss: 1.6094, f1: 0.051, accuracy: 0.148\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 57, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.156, accuracy: 0.455\n",
            "TRAIN Epoch: 57 | Epoch metrics | loss: 1.6094, f1: 0.058, accuracy: 0.170, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 57/60 [1:28:25<03:37, 72.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 57 | Epoch metrics | loss: 1.6094, f1: 0.076, accuracy: 0.189\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 58, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.062, accuracy: 0.182\n",
            "TRAIN Epoch: 58 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.168, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 58/60 [1:29:37<02:24, 72.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 58 | Epoch metrics | loss: 1.6094, f1: 0.067, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 59, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.086, accuracy: 0.273\n",
            "TRAIN Epoch: 59 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 59/60 [1:30:50<01:12, 72.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 59 | Epoch metrics | loss: 1.6094, f1: 0.061, accuracy: 0.169\n",
            "--------------------------------------------------\n",
            " TRAIN Epoch: 60, batch: 70 | Batch metrics | loss: 1.6094, f1: 0.086, accuracy: 0.273\n",
            "TRAIN Epoch: 60 | Epoch metrics | loss: 1.6094, f1: 0.057, accuracy: 0.169, learning rate: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [1:32:02<00:00, 92.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION  Epoch: 60 | Epoch metrics | loss: 1.6094, f1: 0.050, accuracy: 0.148\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTlfFfXmXlJW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}